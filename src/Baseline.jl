using StatsBase
using Catch22
import StatsBase.std

function reStandardise(F::AbstractArray)
    idxs = vec(nanrows(F) .| constantrows(F))
    ğ›” = StatsBase.std(F, dims=2)
    ğ› = mean(F, dims=2)
    ğ›”[idxs] .= Inf
    return X -> normalise(X, ğ›, ğ›”, standardise, 2)
end
export reStandardise

function reZero(F::AbstractArray, Î±::Float64=10.0)
    # We want to adjust a baseline data set so that features have a variance of 0 if the constant baseline is similar to the high dimensional baseline  (otherwise, the baseline does not change variance).
    # For this, a hyperbolic function of constant and high dimensional baseline variances is used to scale the output
    ğ›” = vec(StatsBase.std(F, dims=2))
    f(X) =  begin
                #C = 1 .- min.((1,), ğ›”./(vec(StatsBase.std(X, dims=2))))
                C = exp.(-Î±.*ğ›”./(vec(StatsBase.std(X, dims=2))))
                ğ› = vec(mean(X, dims=2))
                return normalise(X, ğ›, C, standardise, 2)
            end
    return f
end
export reZero


# ------------------------------------------------------------------------------------------------ #
#                            Combine a high and low dimensional baseline                           #
# ------------------------------------------------------------------------------------------------ #
function reScale(x::AbstractVector, f::Function=_self)
    Ïƒ = std(x)
    Ïƒâ€² = f(Ïƒ)
    return Ïƒâ€².*x./Ïƒ
end
function reScale(F::AbstractArray, f::Vector)
    Fâ€² = deepcopy(F)
    for r = 1:size(F, 1)
        Fâ€²[r, :] = reScale(Fâ€²[r, :] , f[r])
    end
   return Fâ€²
end
function reScale(F::AbstractFeatureArray, f::AbstractFeatureVector)
    (Fáµ£, fáµ£) = intersectFeatures(F, f) # Assumes fáµ£ has all of the features of Fáµ£
    reScale(Fáµ£, vec(fáµ£))
end
function hiloScale(Fâ‚—::Array{Float64, 2}, Fâ‚•::Array{Float64, 2},
                    interval::Function=(x, y) -> NonstationaryProcesses.rampInterval(0, 1, x, y))
    # interval gives a function of Ïƒ, the test variance, with parameters Ïƒâ‚— and Ïƒâ‚•
    if size(Fâ‚—, 1) != size(Fâ‚•, 1)
        error("High and low dimensional baselines do not have the same number of features")
    end
    ğ›”â‚—, ğ›”â‚• = std(Fâ‚—, dims=2), std(Fâ‚•, dims=2)
    ğŸ = interval.(vec(ğ›”â‚—), vec(ğ›”â‚•))
    return F -> reScale(F, ğŸ)
end
function hiloScale(Fâ‚—::AbstractFeatureMatrix, Fâ‚•::AbstractFeatureMatrix,
    interval::Function=(x, y) -> NonstationaryProcesses.rampInterval(0, 1, x, y))
    # interval gives a function of Ïƒ, the test variance, with parameters Ïƒâ‚— and Ïƒâ‚•
    if any(Catch22.featureDims(Fâ‚—) .!= Catch22.featureDims(Fâ‚•))
        error("High and low dimensional baselines do not have the same features")
    end
    ğ›”â‚—, ğ›”â‚• = std(Fâ‚—, dims=2), std(Fâ‚•, dims=2)
    ğ›”â‚•[ğ›”â‚• .< ğ›”â‚—] .= Inf
    #ğ›”â‚•[ğ›”â‚• .< 2.0*ğ›”â‚—] .= Inf # Will need a better threshold
    ğŸ = interval.(vec(ğ›”â‚—), vec(ğ›”â‚•))
    ğŸ = Catch22.featureVector(ğŸ, Catch22.featureDims(Fâ‚—))
    return F -> reScale(F, ğŸ)
end
export hiloScale

# ------------------------------------------------------------------------------------------------ #
#                                    Scale a baseline using PCA                                    #
# ------------------------------------------------------------------------------------------------ #
function orthonormalise(F::AbstractArray, dimensionalityReduction=principalComponents)
    M = dimensionalityReduction(F)
    FÌ‚ = embed(M, F)
    return (FÌ‚, M)
end
function orthonormalise(F::AbstractFeatureMatrix, dimensionalityReduction=principalComponents)
    FÌ‚, M = orthonormalise(Array(F), dimensionalityReduction)
    FÌ‚ = Catch22.featureMatrix(FÌ‚, [Symbol("PC$x") for x âˆˆ 1:size(FÌ‚, 1)])
    return FÌ‚, M
end
export orthonormalise

function orthonormalBaseline(F::AbstractArray, dimensionalityReduction=principalComponents)
    function ğ‘(F_test)
        @assert size(F, 1) == size(F_test, 1)
        FÌ‚, M = orthonormalise(F, dimensionalityReduction)
        F_out = embed(M, Array(F_test))
    end
    return ğ‘
end
function orthonormalBaseline(F::AbstractFeatureMatrix, dimensionalityReduction=principalComponents)
    function ğ‘(F_test)
        FÌ‚_test, FÌ‚ = intersectFeatures(F_test, F)
        FÌ‚, M = orthonormalise(FÌ‚, dimensionalityReduction)
        F_out = embed(M, Array(FÌ‚_test))
        F_out = Catch22.featureMatrix(F_out, [Symbol("PC$x") for x âˆˆ 1:size(F_out, 1)])
    end
    return ğ‘
end
export orthonormalBaseline

function orthonormalHiloBaseline(F::AbstractFeatureArray, â„±â‚—::AbstractFeatureArray, â„±â‚•::AbstractFeatureArray; interval::Function=(x, y) -> NonstationaryProcesses.rampInterval(0, 1, x, y))
    F, â„±â‚—, â„±â‚• = intersectFeatures(F, â„±â‚—, â„±â‚•) # Intersects to the feature set of F
    â„±â‚•â€², M = orthonormalise(Array(â„±â‚•))
    â„±â€² = Catch22.featureMatrix(â„±â‚•â€², [Symbol("PC$x") for x âˆˆ 1:size(â„±â‚•â€², 1)])
    Fâ€² = embed(M, F)
    â„±â€²â‚— = embed(M, â„±â‚—)
    ğ‘â€² = hiloScale(Array(â„±â€²â‚—), Array(â„±â‚•â€²), interval)
    return ğ‘â€²(Fâ€²)
end
orthonormalHiloBaseline(â„±â‚—::AbstractFeatureArray, â„±â‚•::AbstractFeatureArray; kwargs...) = F -> orthonormalHiloBaseline(F, â„±â‚—, â„±â‚•; kwargs...)
export orthonormalHiloBaseline




# ------------------------------------------------------------------------------------------------ #
#                               Filter features using correlations/MI                              #
# ------------------------------------------------------------------------------------------------ #
function meanDependence(f, F; metric=StatsBase.corspearman)
    Ï = [metric(f, fâ€²) for fâ€² âˆˆ eachrow(F)]
    ÏÌ„ = mean(abs.(Ï))
end

function meanDependence(F; metric=StatsBase.corspearman)
    ğŸ = zeros(size(F, 1))
    ğŸ = [meanDependence(F[x, :], F[setdiff(1:size(F, 1), [x]), :]; metric) for x âˆˆ 1:size(F, 1)]
end
export meanDependence

function dependencyFilter(F, threshold=0.3; metric=StatsBase.corspearman, iterations=Inf, direction=:min)
    # Iteratively filter features according to algorithm in Ben's thesis, page 214
    iteration = 0
    if direction == :min
        direction = 1
    elseif direction == :max
        direction = -1
    end
    IÌ„ = zeros(size(F, 1)) .+ (-direction + 1)/2
    while any(direction.*IÌ„ .< direction.*threshold) && iteration < iterations # Yes IÌ„ keeps changing size
        IÌ„ = meanDependence(F; metric)
        I, f = findmin(direction.*IÌ„)
        F = F[setdiff(1:lastindex(F, 1), [f]), :]
        iteration += 1
    end
    return F
end
export dependencyFilter




# ------------------------------------------------------------------------------------------------ #
#                                      Pick some better names                                      #
# ------------------------------------------------------------------------------------------------ #

# * We have four baselines associated with rescaling variances, plus the PCA whitening rotation that can be performed before all four rescalings

# ------------------------------------------- Rescaling ------------------------------------------ #
"""
Standardise the test features. Alternatively, just use the normalisation field of an Inference.
"""
standardbaseline(F::AbstractArray) = standardise(F, 2)
standardbaseline() = F -> standardbaseline(F)
export standardbaseline


"""
Scale the features so that the variance of a constant baseline is zero. Do this by setting mapping variances less than Ïƒâ‚— to 0, but keeping a gradient of 1.0 afterwards. Zscore features, zscore baseline from features and then map
"""
function lowbaseline(Fâ‚—::AbstractArray)
    interval = x -> NonstationaryProcesses.rampOn(0.0, 1.0, x, x+1.0)
    function lowscale(F::AbstractArray)
        FÌ‚, FÌ‚â‚— = intersectFeatures(F, Fâ‚—)
        ğ›” = StatsBase.std(FÌ‚, dims=2)
        ğ› = StatsBase.mean(FÌ‚, dims=2)
        FÌ‚â‚— = normalise(FÌ‚â‚—, ğ›, ğ›”, standardise, 2)
        FÌ‚ = normalise(FÌ‚, ğ›, ğ›”, standardise, 2)
        ğ›” = StatsBase.std(FÌ‚, dims=2)
        ğ› = StatsBase.mean(FÌ‚, dims=2)
        ğ›”â‚— = StatsBase.std(FÌ‚â‚—, dims=2)
        ğ›â‚— = StatsBase.mean(FÌ‚â‚—, dims=2)
        ğŸ = interval.(vec(ğ›”â‚—))
        if typeof(F) <: AbstractFeatureArray
            ğŸ = Catch22.FeatureVector(ğŸ, Catch22.featureDims(FÌ‚â‚—))
        end
        return reScale(FÌ‚, ğŸ)
    end
    return lowscale
end
export lowbaseline

"""
Scale the features so that the variance of a high dimensional baselines is unity. Do this as an inverval with a constant variance of 0.0
"""
function highbaseline(Fâ‚•::AbstractArray)
    Fâ‚— = zeros(size(Fâ‚•))
    hiloScale(Fâ‚—, Fâ‚•)
end
function highbaseline(Fâ‚•::AbstractFeatureArray)
    Fâ‚•, Fâ‚— = intersectFeatures(Fâ‚•, zeros(size(Fâ‚•)))
    hiloScale(Fâ‚—, Fâ‚•)
end
export highbaseline

"""
Scale the features so that their variances map to a rampInterval between the low (0) and high dim (1) baselines.
"""
function intervalbaseline(Fâ‚—::AbstractArray, Fâ‚•::AbstractArray)
    hiloScale(Fâ‚—, Fâ‚•)
end
export highbaseline


# ---------------------------------- High dim orthonormalisation --------------------------------- #
"""
Add this to any baseline variables and the Inference normalisation transform into the high dim. whitened space
"""
orthonormaliseto(Fâ‚•::AbstractArray, dimensionalityReduction=principalComponents) = orthonormalBaseline(Fâ‚•, dimensionalityReduction)
export orthonormaliseto


